{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = \"Two Altar Boys Arrested for Putting Weed in the Censer Burner\"\n",
    "body = \"\"\"What started as a joke ended with the future of two altar boys from Spain. They were detained overnight, after having surprised them putting weed in the censer-burner of the Cathedral of Santiago de Compostela.\n",
    "The censer-burner is used the Cathedral of Santiago de Compostela to celebrate the Epiphany of the Lord. Several assistants stated that in this occasion the holy precinct was suddenly covered in an odd smell “it did not smell as always, it was a familiar smell but I could not relate it to anything, but in my son’s bedroom sometimes smell like that”.\n",
    "Following the Mass, these altar boys were arrested by the police after confirming that the strange smell was correspond to marijuana, “it was a joke, the idea came during the Christmas Eve mass, we bought no more than half a kilo of Mary Jane and we drop it inside the censer-burner, we are sure that people has left of the Cathedral happier more than ever”. Finally, they were freed without charge but they will not be able to discharge their functions as altar boys any more.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'test', 'text']\n",
      "['This', 'is', 'also', 'not', 'a', 'test', 'text']\n"
     ]
    }
   ],
   "source": [
    "bowA = doc1.split(\" \")\n",
    "bowB = doc2.split(\" \")\n",
    "print(bowA)\n",
    "print(bowB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This', 'a', 'also', 'is', 'not', 'test', 'text'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSet = set(bowA).union(set(bowB))\n",
    "wordSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'also': 0, 'test': 0, 'This': 0, 'not': 0, 'text': 0, 'a': 0, 'is': 0}\n",
      "{'also': 0, 'test': 0, 'This': 0, 'not': 0, 'text': 0, 'a': 0, 'is': 0}\n"
     ]
    }
   ],
   "source": [
    "wordDictA = dict.fromkeys(wordSet, 0)\n",
    "wordDictB = dict.fromkeys(wordSet, 0)\n",
    "print(wordDictA)\n",
    "print(wordDictB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'also': 0, 'test': 1, 'This': 1, 'not': 0, 'text': 1, 'a': 1, 'is': 1}\n",
      "{'also': 1, 'test': 1, 'This': 1, 'not': 1, 'text': 1, 'a': 1, 'is': 1}\n"
     ]
    }
   ],
   "source": [
    "for word in bowA:\n",
    "    wordDictA[word] +=1\n",
    "for word in bowB:\n",
    "    wordDictB[word] +=1\n",
    "print(wordDictA)\n",
    "print(wordDictB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>also</th>\n",
       "      <th>test</th>\n",
       "      <th>This</th>\n",
       "      <th>not</th>\n",
       "      <th>text</th>\n",
       "      <th>a</th>\n",
       "      <th>is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   also  test  This  not  text  a  is\n",
       "0     0     1     1    0     1  1   1\n",
       "1     1     1     1    1     1  1   1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count /float(bowCount)\n",
    "    return tfDict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'also': 0.0, 'test': 0.2, 'This': 0.2, 'not': 0.0, 'text': 0.2, 'a': 0.2, 'is': 0.2}\n",
      "{'also': 0.14285714285714285, 'test': 0.14285714285714285, 'This': 0.14285714285714285, 'not': 0.14285714285714285, 'text': 0.14285714285714285, 'a': 0.14285714285714285, 'is': 0.14285714285714285}\n"
     ]
    }
   ],
   "source": [
    "print(computeTF(wordDictA,bowA))\n",
    "print(computeTF(wordDictB,bowB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    idfDict = {}\n",
    "    n = len(docList)\n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] +=1\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(n/float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'also': 0.3010299956639812, 'test': 0.3010299956639812, 'This': 0.3010299956639812, 'not': 0.3010299956639812, 'text': 0.3010299956639812, 'a': 0.3010299956639812, 'is': 0.3010299956639812}\n"
     ]
    }
   ],
   "source": [
    "print(computeIDF([wordDictA, wordDictB]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = \"\"\"Based on data and analyses prevented by its high-level technical experts committee on coronavirus disease (Covid-19), the health ministry is likely to extend testing protocols to include rapid antibody testing for everyone at risk, including those outside hotspot areas.\n",
    "\n",
    "Once approved, these guidelines will replace the Indian Council of Medical Research’s interim advisory issued on April 2 that limited rapid antibody testing to hotspot areas.\n",
    "\n",
    "Unlike the RT-PCR test that detects the virus’ genetic material (RNA) in throat swabs to diagnose current infection, rapid antibody test indicate if a person has been infected and has immunity.\n",
    "\n",
    "The simple blood test, which takes 15-20 minutes to give results, will help identify people who were infected but never diagnosed, which will help map undetected infection and give the correct extend of the epidemic.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
